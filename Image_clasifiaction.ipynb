{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DhkFVYnjSttD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BJDELeeDT4Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow as tf\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "V3I83jviUYoP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import batchnorm\n",
        "bs = 1\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout2d(0.1)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout2d(0.2)\n",
        "        )\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128)\n",
        "        )\n",
        "        self.conv6 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout2d(0.3)\n",
        "        )\n",
        "        self.conv7 = nn.Sequential(\n",
        "            nn.Conv2d(128,256,kernel_size=4,padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Dropout2d(0.3)\n",
        "        )\n",
        "        self.conv8 = nn.Sequential(\n",
        "            nn.Conv2d(256,256,kernel_size=3,padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(256, 10)  # number of classes =10\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv8(self.conv7(self.conv6(self.conv5(self.conv4(self.conv3(self.conv2(self.conv1(x))))))))        \n",
        "        x = F.avg_pool2d(x, kernel_size=x.shape[2:])\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        x = self.fc(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "x1dIbkkiV5RD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, epoch, optimizer, criterion):\n",
        "    \n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    for batch_idx, (data, target) in enumerate(dataloader):\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "        output = model(data)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        pred_cls = output.max(1)[1]\n",
        "        correct = pred_cls.eq(target.long().data).cpu().sum()\n",
        "        \n",
        "        train_acc.append(correct.item()/data.shape[0])\n",
        "        train_loss.append(loss.item())\n",
        "        \n",
        "        if batch_idx % 50 == 0:\n",
        "            print('\\rTrain Epoch: {} [({:.0f}%)]\\tLoss: {:.3f}\\tAcc: {:.2f}%'.format(\n",
        "            epoch+1, 100. * batch_idx / len(dataloader), np.mean(train_loss), 100*np.mean(train_acc)), end=\"\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "sHL5OdxO9sYU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model,testdataloder):\n",
        "  \n",
        "  val_acc=[]\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, target in testdataloder:\n",
        "      data, target = data.cuda(), target.cuda()\n",
        "      output=model(data)\n",
        "      pred_cls=output.max(1)[1]\n",
        "      correct=pred_cls.eq(target.long().data).cpu().sum()\n",
        "      val_acc.append(correct.item()/data.shape[0])\n",
        "  print(\"val_acc :{:2f}%\".format(100*np.mean(val_acc)))\n",
        "  return np.mean(val_acc)"
      ],
      "metadata": {
        "id": "2GP6hGJMToFC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}\n"
      ],
      "metadata": {
        "id": "7m02bR2xPju3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \n",
        "    #Loading the dataset \n",
        "    \n",
        "    cifar_train_dataset=torchvision.datasets.CIFAR10(\n",
        "        root = './data',\n",
        "        transform = transforms.Compose([\n",
        "                transforms.Resize([32, 32]),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(), \n",
        "                transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5, 0.5, 0.5])\n",
        "        ]),\n",
        "        download=True,\n",
        "        train=True\n",
        "    )\n",
        "    \n",
        "    # Defining the dataloader\n",
        "    \n",
        "    dataloader = torch.utils.data.DataLoader(cifar_train_dataset, batch_size=64, shuffle = True, num_workers=4)\n",
        "    \n",
        "    cifar_test_dataset=torchvision.datasets.CIFAR10(\n",
        "        root = './data',\n",
        "        transform = transforms.Compose([\n",
        "                transforms.Resize([32, 32]),\n",
        "                transforms.ToTensor(), \n",
        "                transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5, 0.5, 0.5])\n",
        "        ]),\n",
        "        download=True,\n",
        "        train=False\n",
        "    )\n",
        "    \n",
        "    testdataloader = torch.utils.data.DataLoader(cifar_test_dataset, batch_size=64, shuffle = False, num_workers=6)\n",
        "    \n",
        "    # defining the model\n",
        "    model = NeuralNet()\n",
        "    # defining the optimizer\n",
        "    optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    criterion=nn.NLLLoss()\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "    \n",
        "    print(\"st of model\",model)\n",
        "\n",
        "    n_epoch=100\n",
        "    best=0\n",
        "    for epoch in range (n_epoch):\n",
        "      train(model,dataloader,epoch,optimizer,criterion)\n",
        "      val_acc=evaluate_model(model,testdataloader)\n",
        "      if val_acc>best:\n",
        "        best=val_acc\n",
        "        torch.save(model.state_dict(),\"best.ckpt\")\n",
        "\n",
        "    print(\"Done\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FVHXjXnlT0eE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "n9U6J4MGQ_sH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}